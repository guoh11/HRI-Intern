# HRI-Intern



## Papers

### Action Anticipation


- `CVPR 2023` Latency Matters: Real-Time Action Forecasting Transformer [[Paper](https://openaccess.thecvf.com/content/CVPR2023/papers/Girase_Latency_Matters_Real-Time_Action_Forecasting_Transformer_CVPR_2023_paper.pdf)] [[Supplementary](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Girase_Latency_Matters_Real-Time_CVPR_2023_supplemental.pdf)]

- `WACV 2023` Intention-Conditioned Long-Term Human Egocentric Action Anticipation [[Paper](https://openaccess.thecvf.com/content/WACV2023/papers/Mascaro_Intention-Conditioned_Long-Term_Human_Egocentric_Action_Anticipation_WACV_2023_paper.pdf)]

- `ECCV 2022` Rethinking Learning Approaches for Long-Term Action Anticipation [[Paper](https://arxiv.org/pdf/2210.11566.pdf)]

- `arXiv 2022` Predicting the Next Action by Modeling the Abstract Goal [[Paper](https://arxiv.org/pdf/2209.05044.pdf)]

- `arXiv 2022` Video + CLIP Baseline [[Technical Report](https://arxiv.org/pdf/2207.00579.pdf)]

- `CVPR 2022` MeMViT: Memory-Augmented Multiscale Vision Transformer for Efficient Long-Term Video Recognition [[Paper](https://openaccess.thecvf.com/content/CVPR2022/papers/Wu_MeMViT_Memory-Augmented_Multiscale_Vision_Transformer_for_Efficient_Long-Term_Video_Recognition_CVPR_2022_paper.pdf)]
- `CVPR 2022` A Hybrid Egocentric Activity Anticipation Framework via Memory-Augmented Recurrent and One-shot Representation Forecasting [[Paper](https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_A_Hybrid_Egocentric_Activity_Anticipation_Framework_via_Memory-Augmented_Recurrent_and_CVPR_2022_paper.pdf)]
- `CVPR 2022` Future Transformer for Long-term Action Anticipation [[Paper](https://openaccess.thecvf.com/content/CVPR2022/papers/Gong_Future_Transformer_for_Long-Term_Action_Anticipation_CVPR_2022_paper.pdf)]
- `CVPRW 2022`  Long-term Action Forecasting Using Multi-headed Attention-based Variational Recurrent Neural Networks [[Paper](https://openaccess.thecvf.com/content/CVPR2022W/ABAW/papers/Loh_Long-Term_Action_Forecasting_Using_Multi-Headed_Attention-Based_Variational_Recurrent_Neural_Networks_CVPRW_2022_paper.pdf)]
- `CVPRW 2022` Long-term Action Forecasting Using Multi-headed Attention-based Variational Recurrent Neural Networks [[Paper](https://openaccess.thecvf.com/content/CVPR2022W/ABAW/papers/Loh_Long-Term_Action_Forecasting_Using_Multi-Headed_Attention-Based_Variational_Recurrent_Neural_Networks_CVPRW_2022_paper.pdf)]
- `WACV 2022` Action anticipation using latent goal learning [[Paper](https://openaccess.thecvf.com/content/WACV2022/papers/Roy_Action_Anticipation_Using_Latent_Goal_Learning_WACV_2022_paper.pdf)]
- `ICCV 2021` Anticipative Video Transformer [[Paper](https://openaccess.thecvf.com/content/ICCV2021/papers/Girdhar_Anticipative_Video_Transformer_ICCV_2021_paper.pdf)] [[Workshop](https://facebookresearch.github.io/AVT/papers/EPICWorkshop2021.pdf)]
- `IJCAI 2021` What If We Could Not See? Counterfactual Analysis for Egocentric Action Anticipation [[Paper](https://www.ijcai.org/proceedings/2021/0182.pdf)]
- `TPAMI 2021` Self-Regulated Learning for Egocentric Video Activity Anticipation [[Paper](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9356220&casa_token=ztuZhFWHuwAAAAAA:5oJ6_QMTSCxfEhlJpuwcji3jlCzF2E-5PeCAH0yd5lxWG61-lKQVttHCEE_M35ZrKFN3RmHtsk4&tag=1)]
- `TPAMI 2021` Forecasting Action Through Contact Representations From First Person Video [[Paper](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9340014&casa_token=M6sXHvJQ5ToAAAAA:_Vk68PpBxu3JkrG4imzmpvVYOwNBkOSALIZ1t9NBaP5OkgRGt0scf8H_qfSqfPO7z57w8weCB1o)]
- `TMM 2021` RESTEP into the Future: Relational Spatio-Temporal Learning for Multi-Person Action Forecasting [[Paper](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9451613&casa_token=2QQXE-BuQuMAAAAA:y8UFyz9l7brIxe-mZMsY8wVKqei7Y-8L7Ilk81oFrGYNaOuP7jM0b4MzMDR3H5xiF-FQ8c1O0Hg)]
- `TIP 2021` Action Anticipation Using Pairwise Human-Object Interactions and Transformers [[Paper](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9546623&casa_token=DWRuhZgJC58AAAAA:EJw36uov4iYtgX6TFtyRcFUzpQiEwFvFzZ1icrmo1PQ2v0lPUW9wdjAilK7O_PbH3-3FguFMPR4)]
- `ECCV 2020` Temporal Aggregate Representations for Long-Range Video Understanding [[Paper](https://arxiv.org/pdf/2006.00830.pdf)]
- 'ECCV 2020' Forecasting Human-Object Interaction: Joint Prediction of Motor Attention and Actions in First Person Video [[Paper](https://arxiv.org/pdf/1911.10967.pdf)]
- `TIP 2020` Forecasting Future Action Sequences With Attention: A New Approach to Weakly Supervised Action Forecasting [[Paper](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9194283&casa_token=3O-g-aIbdc0AAAAA:SmCMOvMKVErC6PgTUv9ZLDRWKgl5jsRGgIJS60KR1hF6mcw_9ftbCnpo0KLZ4Lg7ui1UbEeWNE0)]
- `TIP 2020` Learning to Anticipate Egocentric Actions by Imagination [[Paper](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9280353&casa_token=bg9n2XdhdVMAAAAA:qXOnX5dj7LoEJHxtsgG1OhjMuvd4GDu-7fNV_n4s9yGTfJOmiyCmc7XaGrxYs1Sw6tLU2mje92o)]
- 'TPAMI 2020' Rolling-Unrolling LSTMs for Action Anticipation from First-Person Video [[Paper](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9088213&casa_token=sAOboJYq5sMAAAAA:lcK_IbDI1NJD9AyQ6WXnkd9Jl-1SMeFNgfMYinh7spMoGzUHMKJ0XZxFMrSc74tXNrD5IuzvY18&tag=1)]
- `ICCV 2019` What Would You Expect? Anticipating Egocentric Actions With Rolling-Unrolling LSTMs and Modality Attention [[Paper](https://openaccess.thecvf.com/content_ICCV_2019/papers/Furnari_What_Would_You_Expect_Anticipating_Egocentric_Actions_With_Rolling-Unrolling_LSTMs_ICCV_2019_paper.pdf)] [[Supplementary](https://openaccess.thecvf.com/content_ICCV_2019/supplemental/Furnari_What_Would_You_ICCV_2019_supplemental.pdf)]
- `ICCV 2019` Predicting the Future: A Jointly Learnt Model for Action Anticipation [[Paper](https://openaccess.thecvf.com/content_ICCV_2019/papers/Gammulle_Predicting_the_Future_A_Jointly_Learnt_Model_for_Action_Anticipation_ICCV_2019_paper.pdf)] [[Supplementary](https://openaccess.thecvf.com/content_ICCV_2019/supplemental/Gammulle_Predicting_the_Future_ICCV_2019_supplemental.pdf)]
- `CVPR 2019` Time-Conditioned Action Anticipation in One Shot [[Paper](https://openaccess.thecvf.com/content_CVPR_2019/papers/Ke_Time-Conditioned_Action_Anticipation_in_One_Shot_CVPR_2019_paper.pdf)]
- `CVPR 2019` Relational Action Forecasting [[Paper](https://openaccess.thecvf.com/content_CVPR_2019/papers/Sun_Relational_Action_Forecasting_CVPR_2019_paper.pdf)]
- `CVPR 2018` When will you do what? - Anticipating Temporal Occurrences of Activities [[Paper](https://openaccess.thecvf.com/content_cvpr_2018/papers/Abu_Farha_When_Will_You_CVPR_2018_paper.pdf)]
- `ECCV 2018` Action Anticipation with RBF Kernelized Feature Mapping RNN [[Paper](https://openaccess.thecvf.com/content_ECCV_2018/papers/Yuge_Shi_Action_Anticipation_with_ECCV_2018_paper.pdf)]
- `ECCVW 2018` Action Anticipation By Predicting Future Dynamic Images [[Paper](https://openaccess.thecvf.com/content_ECCVW_2018/papers/11131/Rodriguez_Action_Anticipation_By_Predicting_Future_Dynamic_Images_ECCVW_2018_paper.pdf)]
- `AAAI 2018` Action Prediction from Videos via Memorizing Hard-to-Predict Samples [[Paper](https://ojs.aaai.org/index.php/AAAI/article/view/12324)]
- `ICCV 2017` First-Person Activity Forecasting with Online Inverse Reinforcement Learning [[Paper](https://openaccess.thecvf.com/content_ICCV_2017/papers/Rhinehart_First-Person_Activity_Forecasting_ICCV_2017_paper.pdf)]
- `BMVC 2017` RED: Reinforced Encoder-Decoder Networks for Action Anticipation [[Paper](https://arxiv.org/pdf/1707.04818.pdf)]
- `ICRA 2016` Recurrent Neural Networks for Driver Activity Anticipation via Sensory-Fusion Architecture [[Paper](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7487478&casa_token=IX3oYg5_uMwAAAAA:DGuERQWj0T2YXSsMydPpU6qtl9Rv6zeAAccUShaFODkb2GT7XHpBgFxr17WTiFTm0MrKy5N6Mgs&tag=1)]
- `ACCV 2016` Long-Term Activity Forecasting using First-Person Vision [[Paper](http://www.cs.cmu.edu/~kkitani/pdf/BK-ACCV16.pdf)]
- `ACCV 2014` Context-Aware Activity Forecasting [[Paper](https://vcg.engr.ucr.edu/sites/default/files/2019-02/accv_2014.pdf)]










### Early Action Prediction


- `CVPR 2023` The Wisdom of Crowds: Temporal Progress Attention for Early Action Prediction [[Paper](https://openaccess.thecvf.com/content/CVPR2023/papers/Stergiou_The_Wisdom_of_Crowds_Temporal_Progressive_Attention_for_Early_Action_CVPR_2023_paper.pdf)]

- `ECCV 2022` ERA: Expert Retrieval and Assembly for Early Action Prediction [[Paper](https://arxiv.org/pdf/2207.09675.pdf)]

- `CVPR 2017` Deep Sequential Context Networks for Action Prediction [[Paper](https://openaccess.thecvf.com/content_cvpr_2017/papers/Kong_Deep_Sequential_Context_CVPR_2017_paper.pdf)]

- `ICCV 2011` Human activity prediction: Early recognition of ongoing activities from streaming videos


### Visual-Language Modeling

- `CVPR 2023` HierVL: Learning Hierarchical Video-Language Embeddings [[Paper](https://arxiv.org/pdf/2301.02311.pdf)]
- `ICPR 2022` Cross-modal Contrastive Distillation for Instructional Activity Anticipation [[Paper](https://arxiv.org/pdf/2201.06734.pdf)]
- `ICCV 2019` VideoBERT: A Joint Model for Video and Language Representation Learning [[Paper](https://openaccess.thecvf.com/content_ICCV_2019/papers/Sun_VideoBERT_A_Joint_Model_for_Video_and_Language_Representation_Learning_ICCV_2019_paper.pdf)]


### Multi-Modal
- `CVPR 2023` MMG-Ego4D: Multi-Modal Generalization in Egocentric Action Recognition [[Paper](https://openaccess.thecvf.com/content/CVPR2023/papers/Gong_MMG-Ego4D_Multimodal_Generalization_in_Egocentric_Action_Recognition_CVPR_2023_paper.pdf)]

- `WACV 2023` Anticipative Feature Fusion Transformer for Multi-Modal Action Anticipation [[Paper](https://openaccess.thecvf.com/content/WACV2023/papers/Zhong_Anticipative_Feature_Fusion_Transformer_for_Multi-Modal_Action_Anticipation_WACV_2023_paper.pdf)]








## Method to compare with

### Ego4D v1


### Ego4D v2



### EPIC-KITCHENS-55


### EPIC-KITCHENS-100











## Datasets

- EPIC-KITCHENS [[Website-100](https://epic-kitchens.github.io/2023)] [[Website-55](https://epic-kitchens.github.io/2020-55.html)]  [[ECCV2018](https://openaccess.thecvf.com/content_ECCV_2018/papers/Dima_Damen_Scaling_Egocentric_Vision_ECCV_2018_paper.pdf), [TPAMI 2021](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9084270&casa_token=F8iR590MEFoAAAAA:wCcb8Uae-ZHvV4X-jZEJACfyYafhTHXe8IJMM-36cus1y4UxFY6nZgRD9EH-kRHbDA-NdwcA0-I&tag=1), [IJCV 2022](https://link.springer.com/article/10.1007/s11263-021-01531-2)]

- Ego4D [[Website](https://ego4d-data.org/)] [[Paper](https://openaccess.thecvf.com/content/CVPR2022/papers/Grauman_Ego4D_Around_the_World_in_3000_Hours_of_Egocentric_Video_CVPR_2022_paper.pdf)]

- Breakfast Actions [[Website](https://serre-lab.clps.brown.edu/resource/breakfast-actions-dataset/)] [[Paper](https://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/Kuehne_The_Language_of_2014_CVPR_paper.pdf)]

- 50 Salads [[Website](https://cvip.computing.dundee.ac.uk/datasets/foodpreparation/50salads/)]

- EGTEA GAZE+ [[Website](https://cbs.ic.gatech.edu/fpv/)]








