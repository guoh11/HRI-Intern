# HRI-Intern


## Papers

### Action Anticipation

- `CVPR 2023` Latency Matters: Real-Time Action Forecasting Transformer [[Paper](https://openaccess.thecvf.com/content/CVPR2023/papers/Girase_Latency_Matters_Real-Time_Action_Forecasting_Transformer_CVPR_2023_paper.pdf)] [[Supplementary](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Girase_Latency_Matters_Real-Time_CVPR_2023_supplemental.pdf)]

- `WACV 2023` Intention-Conditioned Long-Term Human Egocentric Action Anticipation [[Paper](https://openaccess.thecvf.com/content/WACV2023/papers/Mascaro_Intention-Conditioned_Long-Term_Human_Egocentric_Action_Anticipation_WACV_2023_paper.pdf)]

- `ECCV 2022` Rethinking Learning Approaches for Long-Term Action Anticipation [[Paper](https://arxiv.org/pdf/2210.11566.pdf)]

- `arXiv 2022` Predicting the Next Action by Modeling the Abstract Goal [[Paper](https://arxiv.org/pdf/2209.05044.pdf)]

- `arXiv 2022` Video + CLIP Baseline [[Technical Report](https://arxiv.org/pdf/2207.00579.pdf)]

- `CVPR 2022` MeMViT: Memory-Augmented Multiscale Vision Transformer for Efficient Long-Term Video Recognition [[Paper](https://openaccess.thecvf.com/content/CVPR2022/papers/Wu_MeMViT_Memory-Augmented_Multiscale_Vision_Transformer_for_Efficient_Long-Term_Video_Recognition_CVPR_2022_paper.pdf)]
- `CVPR 2022` A Hybrid Egocentric Activity Anticipation Framework via Memory-Augmented Recurrent and One-shot Representation Forecasting [[Paper](https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_A_Hybrid_Egocentric_Activity_Anticipation_Framework_via_Memory-Augmented_Recurrent_and_CVPR_2022_paper.pdf)]
- `CVPR 2022` Future Transformer for Long-term Action Anticipation [[Paper](https://openaccess.thecvf.com/content/CVPR2022/papers/Gong_Future_Transformer_for_Long-Term_Action_Anticipation_CVPR_2022_paper.pdf)]
- `CVPRW 2022`  Long-term Action Forecasting Using Multi-headed Attention-based Variational Recurrent Neural Networks [[Paper](https://openaccess.thecvf.com/content/CVPR2022W/ABAW/papers/Loh_Long-Term_Action_Forecasting_Using_Multi-Headed_Attention-Based_Variational_Recurrent_Neural_Networks_CVPRW_2022_paper.pdf)]
- `CVPRW 2022` Long-term Action Forecasting Using Multi-headed Attention-based Variational Recurrent Neural Networks [[Paper](https://openaccess.thecvf.com/content/CVPR2022W/ABAW/papers/Loh_Long-Term_Action_Forecasting_Using_Multi-Headed_Attention-Based_Variational_Recurrent_Neural_Networks_CVPRW_2022_paper.pdf)]
- `WACV 2022` Action anticipation using latent goal learning [[Paper](https://openaccess.thecvf.com/content/WACV2022/papers/Roy_Action_Anticipation_Using_Latent_Goal_Learning_WACV_2022_paper.pdf)]
- `ICCV 2021` Anticipative Video Transformer [[Paper](https://openaccess.thecvf.com/content/ICCV2021/papers/Girdhar_Anticipative_Video_Transformer_ICCV_2021_paper.pdf)] [[Workshop](https://facebookresearch.github.io/AVT/papers/EPICWorkshop2021.pdf)]
- `CVPR 2021` Learning the Predictability of the Future [[Paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Suris_Learning_the_Predictability_of_the_Future_CVPR_2021_paper.pdf)]
- `IJCAI 2021` What If We Could Not See? Counterfactual Analysis for Egocentric Action Anticipation [[Paper](https://www.ijcai.org/proceedings/2021/0182.pdf)]
- `TPAMI 2021` Self-Regulated Learning for Egocentric Video Activity Anticipation [[Paper](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9356220&casa_token=ztuZhFWHuwAAAAAA:5oJ6_QMTSCxfEhlJpuwcji3jlCzF2E-5PeCAH0yd5lxWG61-lKQVttHCEE_M35ZrKFN3RmHtsk4&tag=1)]
- `TPAMI 2021` Forecasting Action Through Contact Representations From First Person Video [[Paper](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9340014&casa_token=M6sXHvJQ5ToAAAAA:_Vk68PpBxu3JkrG4imzmpvVYOwNBkOSALIZ1t9NBaP5OkgRGt0scf8H_qfSqfPO7z57w8weCB1o)]
- `TMM 2021` RESTEP into the Future: Relational Spatio-Temporal Learning for Multi-Person Action Forecasting [[Paper](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9451613&casa_token=2QQXE-BuQuMAAAAA:y8UFyz9l7brIxe-mZMsY8wVKqei7Y-8L7Ilk81oFrGYNaOuP7jM0b4MzMDR3H5xiF-FQ8c1O0Hg)]
- `TIP 2021` Action Anticipation Using Pairwise Human-Object Interactions and Transformers [[Paper](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9546623&casa_token=DWRuhZgJC58AAAAA:EJw36uov4iYtgX6TFtyRcFUzpQiEwFvFzZ1icrmo1PQ2v0lPUW9wdjAilK7O_PbH3-3FguFMPR4)]
- `ECCV 2020` Temporal Aggregate Representations for Long-Range Video Understanding [[Paper](https://arxiv.org/pdf/2006.00830.pdf)] [[Technical Report](https://arxiv.org/pdf/2106.03152v2.pdf)]
- `ECCV 2020` Forecasting Human-Object Interaction: Joint Prediction of Motor Attention and Actions in First Person Video [[Paper](https://arxiv.org/pdf/1911.10967.pdf)]
- `TIP 2020` Forecasting Future Action Sequences With Attention: A New Approach to Weakly Supervised Action Forecasting [[Paper](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9194283&casa_token=3O-g-aIbdc0AAAAA:SmCMOvMKVErC6PgTUv9ZLDRWKgl5jsRGgIJS60KR1hF6mcw_9ftbCnpo0KLZ4Lg7ui1UbEeWNE0)]
- `TIP 2020` Learning to Anticipate Egocentric Actions by Imagination [[Paper](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9280353&casa_token=bg9n2XdhdVMAAAAA:qXOnX5dj7LoEJHxtsgG1OhjMuvd4GDu-7fNV_n4s9yGTfJOmiyCmc7XaGrxYs1Sw6tLU2mje92o)]
- `TPAMI 2020` Rolling-Unrolling LSTMs for Action Anticipation from First-Person Video [[Paper](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9088213&casa_token=sAOboJYq5sMAAAAA:lcK_IbDI1NJD9AyQ6WXnkd9Jl-1SMeFNgfMYinh7spMoGzUHMKJ0XZxFMrSc74tXNrD5IuzvY18&tag=1)]
- `ICCV 2019` What Would You Expect? Anticipating Egocentric Actions With Rolling-Unrolling LSTMs and Modality Attention [[Paper](https://openaccess.thecvf.com/content_ICCV_2019/papers/Furnari_What_Would_You_Expect_Anticipating_Egocentric_Actions_With_Rolling-Unrolling_LSTMs_ICCV_2019_paper.pdf)] [[Supplementary](https://openaccess.thecvf.com/content_ICCV_2019/supplemental/Furnari_What_Would_You_ICCV_2019_supplemental.pdf)]
- `ICCV 2019` Predicting the Future: A Jointly Learnt Model for Action Anticipation [[Paper](https://openaccess.thecvf.com/content_ICCV_2019/papers/Gammulle_Predicting_the_Future_A_Jointly_Learnt_Model_for_Action_Anticipation_ICCV_2019_paper.pdf)] [[Supplementary](https://openaccess.thecvf.com/content_ICCV_2019/supplemental/Gammulle_Predicting_the_Future_ICCV_2019_supplemental.pdf)]
- `ICCVW 2019` Uncertainty-Aware Anticipation of Activities [[Paper](https://openaccess.thecvf.com/content_ICCVW_2019/papers/HBU/Abu_Farha_Uncertainty-Aware_Anticipation_of_Activities_ICCVW_2019_paper.pdf)]
- `CVPR 2019` Time-Conditioned Action Anticipation in One Shot [[Paper](https://openaccess.thecvf.com/content_CVPR_2019/papers/Ke_Time-Conditioned_Action_Anticipation_in_One_Shot_CVPR_2019_paper.pdf)]
- `CVPR 2019` Relational Action Forecasting [[Paper](https://openaccess.thecvf.com/content_CVPR_2019/papers/Sun_Relational_Action_Forecasting_CVPR_2019_paper.pdf)]
- `CVPR 2018` When will you do what? - Anticipating Temporal Occurrences of Activities [[Paper](https://openaccess.thecvf.com/content_cvpr_2018/papers/Abu_Farha_When_Will_You_CVPR_2018_paper.pdf)]
- `ECCV 2018` Action Anticipation with RBF Kernelized Feature Mapping RNN [[Paper](https://openaccess.thecvf.com/content_ECCV_2018/papers/Yuge_Shi_Action_Anticipation_with_ECCV_2018_paper.pdf)]
- `ECCVW 2018` Action Anticipation By Predicting Future Dynamic Images [[Paper](https://openaccess.thecvf.com/content_ECCVW_2018/papers/11131/Rodriguez_Action_Anticipation_By_Predicting_Future_Dynamic_Images_ECCVW_2018_paper.pdf)]
- `AAAI 2018` Action Prediction from Videos via Memorizing Hard-to-Predict Samples [[Paper](https://ojs.aaai.org/index.php/AAAI/article/view/12324)]
- `ICCV 2017` First-Person Activity Forecasting with Online Inverse Reinforcement Learning [[Paper](https://openaccess.thecvf.com/content_ICCV_2017/papers/Rhinehart_First-Person_Activity_Forecasting_ICCV_2017_paper.pdf)]
- `BMVC 2017` RED: Reinforced Encoder-Decoder Networks for Action Anticipation [[Paper](https://arxiv.org/pdf/1707.04818.pdf)]
- `CVPR 2016` Anticipating Visual Representations from Unlabeled Video [[Paper](https://openaccess.thecvf.com/content_cvpr_2016/papers/Vondrick_Anticipating_Visual_Representations_CVPR_2016_paper.pdf)]
- `ICRA 2016` Recurrent Neural Networks for Driver Activity Anticipation via Sensory-Fusion Architecture [[Paper](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7487478&casa_token=IX3oYg5_uMwAAAAA:DGuERQWj0T2YXSsMydPpU6qtl9Rv6zeAAccUShaFODkb2GT7XHpBgFxr17WTiFTm0MrKy5N6Mgs&tag=1)]
- `TIP 2016` A Poisson Process Model For Activity Forecasting [[Paper](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7532978&casa_token=4VVjhkpHKv0AAAAA:UiHm90Z3DrL3yYOmOxB8J3hWtdk4-xDQuz3a4KzqoOdH66phO4u20fIRgTtdiS5AO0I__oZ7rrU)]
- `ACCV 2016` Long-Term Activity Forecasting using First-Person Vision [[Paper](http://www.cs.cmu.edu/~kkitani/pdf/BK-ACCV16.pdf)]
- `ACCV 2014` Context-Aware Activity Forecasting [[Paper](https://vcg.engr.ucr.edu/sites/default/files/2019-02/accv_2014.pdf)]



### Visual-Language Modeling

- `CVPR 2023` HierVL: Learning Hierarchical Video-Language Embeddings [[Paper](https://arxiv.org/pdf/2301.02311.pdf)]
- `ACL 2023` Text-Derived Knowledge Helps Vision: A Simple Cross-modal Distillation for Video-based Action Anticipation [[Paper](https://aclanthology.org/2023.findings-eacl.141.pdf)]
- `CVPR 2022` HOP: History-and-Order Aware Pre-training for Vision-and-Language Navigation [[Paper](https://openaccess.thecvf.com/content/CVPR2022/papers/Qiao_HOP_History-and-Order_Aware_Pre-Training_for_Vision-and-Language_Navigation_CVPR_2022_paper.pdf)] [[Supplementary](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Qiao_HOP_History-and-Order_Aware_CVPR_2022_supplemental.pdf)]
- `ICPR 2022` Cross-modal Contrastive Distillation for Instructional Activity Anticipation [[Paper](https://arxiv.org/pdf/2201.06734.pdf)]
- `arXiv 2022` Socratic Models: Composing Zero-Shot Multimodal Reasoning with Language [[Paper](https://arxiv.org/pdf/2204.00598.pdf)]
- `NIPS 2021` History Aware Multimodal Transformer for Vision-and-Language Navigation [[Paper](https://proceedings.neurips.cc/paper_files/paper/2021/file/2e5c2cb8d13e8fba78d95211440ba326-Paper.pdf)]
- `ICCV 2019` VideoBERT: A Joint Model for Video and Language Representation Learning [[Paper](https://openaccess.thecvf.com/content_ICCV_2019/papers/Sun_VideoBERT_A_Joint_Model_for_Video_and_Language_Representation_Learning_ICCV_2019_paper.pdf)]
- `arXiv 2019` Harry Potter and the Action Prediction Challenge from Natural Language [[Paper](https://arxiv.org/pdf/1905.11037.pdf)]


### Multi-Modal
- `CVPR 2023` MMG-Ego4D: Multi-Modal Generalization in Egocentric Action Recognition [[Paper](https://openaccess.thecvf.com/content/CVPR2023/papers/Gong_MMG-Ego4D_Multimodal_Generalization_in_Egocentric_Action_Recognition_CVPR_2023_paper.pdf)]

- `WACV 2023` Anticipative Feature Fusion Transformer for Multi-Modal Action Anticipation [[Paper](https://openaccess.thecvf.com/content/WACV2023/papers/Zhong_Anticipative_Feature_Fusion_Transformer_for_Multi-Modal_Action_Anticipation_WACV_2023_paper.pdf)]



### Uncertainty Modeling
- `NIPS 2018` Predictive Uncertainty Estimation via Prior Networks [[Paper](https://proceedings.neurips.cc/paper/2018/file/3ea2db50e62ceefceaf70a9d9a56a6f4-Paper.pdf)]
- `NIPS 2017` What Uncertainties Do We Need in Bayesian Deep Learning for Computer Vision? [[Paper](https://proceedings.neurips.cc/paper/2017/file/2650d6089a6d640c5e85b2b88265dc2b-Paper.pdf)]
- `ICML 2015` Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning [[Paper](http://proceedings.mlr.press/v48/gal16.pdf)]


### "Uncertainty" for Action Related Applications
- `ECCV 2022` Dual-Evidential Learning for Weakly-supervised Temporal Action Localization [[Paper](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136640190.pdf)]
- `ECCV 2022` Uncertainty-Based Spatial-Temporal Attention for Online Action Detection [[Paper](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136640068.pdf)]
- `CVPR 2022` Uncertainty-Guided Probabilistic Transformer for Complex Action Recognition [[Paper](https://openaccess.thecvf.com/content/CVPR2022/papers/Guo_Uncertainty-Guided_Probabilistic_Transformer_for_Complex_Action_Recognition_CVPR_2022_paper.pdf)]
- `IJCAI 2022` Uncertainty-Aware Representation Learning for Action Segmentation [[Paper](https://www.ijcai.org/proceedings/2022/0115.pdf)]
- `IET 2022` Class-wise boundary regression by uncertainty in temporal action detection [[Paper](https://ietresearch.onlinelibrary.wiley.com/doi/pdf/10.1049/ipr2.12599)]
- `TPAMI 2022` Uncertainty Guided Collaborative Training for Weakly Supervised and Unsupervised Temporal Action Localization [[Paper](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9864260&casa_token=exKh8rKa-JEAAAAA:CMXhVqUAM7lZJAETUsu7H_l3x5OYFlmOqLC_azgSGaRr5Qqmexv1DgPqT861EDRV1GIe7CL0JhA&tag=1)]
- `CVPR 2021` Uncertainty Guided Collaborative Training for Weakly Supervised Temporal Action Localization [[Paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Yang_Uncertainty_Guided_Collaborative_Training_for_Weakly_Supervised_Temporal_Action_Detection_CVPR_2021_paper.pdf)]
- `AAAI 2021` Weakly-supervised Temporal Action Localization by Uncertainty Modeling [[Paper](https://arxiv.org/pdf/2006.07006.pdf)]
- `ECCV 2020` Uncertainty-Aware Weakly Supervised Action Detection from Untrimmed Videos [[Paper](https://arxiv.org/pdf/2007.10703.pdf)]
- `BMVC 2020` Refinement of Boundary Regression Using Uncertainty in Temporal Action Localization [[Paper](https://www.bmvc2020-conference.com/assets/papers/0391.pdf)]
- `ICCV 2019` Robust Person Re-identification by Modelling Feature Uncertainty [[Paper](https://openaccess.thecvf.com/content_ICCV_2019/papers/Yu_Robust_Person_Re-Identification_by_Modelling_Feature_Uncertainty_ICCV_2019_paper.pdf)]
- `CVPR 2019` Bayesian Hierarchical Dynamic Model for Human Action Recognition [[Paper](https://openaccess.thecvf.com/content_CVPR_2019/papers/Zhao_Bayesian_Hierarchical_Dynamic_Model_for_Human_Action_Recognition_CVPR_2019_paper.pdf)]
- `ECCV 2018` What do I Annotate Next? An Empirical Study of Active Learning for Action Localization [[Paper](https://openaccess.thecvf.com/content_ECCV_2018/papers/Fabian_Caba_What_do_I_ECCV_2018_paper.pdf)]





## Leaderboard

### Ego4D v1

### Ego4D v2

### EPIC-KITCHENS-55

### EPIC-KITCHENS-100




## Datasets

- EPIC-KITCHENS [[Website-100](https://epic-kitchens.github.io/2023)] [[Website-55](https://epic-kitchens.github.io/2020-55.html)]  [[ECCV2018](https://openaccess.thecvf.com/content_ECCV_2018/papers/Dima_Damen_Scaling_Egocentric_Vision_ECCV_2018_paper.pdf), [TPAMI 2021](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9084270&casa_token=F8iR590MEFoAAAAA:wCcb8Uae-ZHvV4X-jZEJACfyYafhTHXe8IJMM-36cus1y4UxFY6nZgRD9EH-kRHbDA-NdwcA0-I&tag=1), [IJCV 2022](https://link.springer.com/article/10.1007/s11263-021-01531-2)]

- Ego4D [[Website](https://ego4d-data.org/)] [[Paper](https://openaccess.thecvf.com/content/CVPR2022/papers/Grauman_Ego4D_Around_the_World_in_3000_Hours_of_Egocentric_Video_CVPR_2022_paper.pdf)]

- Breakfast Actions [[Website](https://serre-lab.clps.brown.edu/resource/breakfast-actions-dataset/)] [[Paper](https://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/Kuehne_The_Language_of_2014_CVPR_paper.pdf)]

- 50 Salads [[Website](https://cvip.computing.dundee.ac.uk/datasets/foodpreparation/50salads/)] [[Paper](https://web.archive.org/web/20170808065305id_/http://cvip.computing.dundee.ac.uk/papers/Stein2013UbiComp.pdf)]

- EGTEA GAZE+ [[Website](https://cbs.ic.gatech.edu/fpv/)] [[Paper](https://openaccess.thecvf.com/content_ECCV_2018/papers/Yin_Li_In_the_Eye_ECCV_2018_paper.pdf)]








